{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model_vanilla_shiftx import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, im_size=256, format='png', jpeg_fallback=True, filename=None):\n",
    "  if a.dtype != np.uint8:\n",
    "      a = a*255\n",
    "  a = np.asarray(a, dtype=np.uint8)\n",
    "  a = cv2.resize(a, (a.shape[1], a.shape[0]))\n",
    "\n",
    "  str_file = io.BytesIO()\n",
    "  PIL.Image.fromarray(a).save(str_file, format)\n",
    "  im_data = str_file.getvalue()\n",
    "  try:\n",
    "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    if filename:\n",
    "        size = (a.shape[1]//2, a.shape[0]//2)\n",
    "        im = PIL.Image.fromarray(a)\n",
    "        im.thumbnail(size,PIL.Image.ANTIALIAS)\n",
    "        im.save('{}.{}'.format(filename, format))\n",
    "        \n",
    "  except IOError:\n",
    "    if jpeg_fallback and format != 'jpeg':\n",
    "      print ('Warning: image was too large to display in format \"{}\"; '\n",
    "             'trying jpeg instead.').format(format)\n",
    "      return imshow(a, format='jpeg')\n",
    "    else:\n",
    "      raise\n",
    "  return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgrid(imarray, cols=5, pad=1):\n",
    "  if imarray.dtype != np.uint8:\n",
    "    raise ValueError('imgrid input imarray must be uint8')\n",
    "  pad = int(pad)\n",
    "  assert pad >= 0\n",
    "  cols = int(cols)\n",
    "  assert cols >= 1\n",
    "  N, H, W, C = imarray.shape\n",
    "  rows = int(np.ceil(N / float(cols)))\n",
    "  batch_pad = rows * cols - N\n",
    "  assert batch_pad >= 0\n",
    "  post_pad = [batch_pad, pad, pad, 0]\n",
    "  pad_arg = [[0, p] for p in post_pad]\n",
    "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n",
    "  H += pad\n",
    "  W += pad\n",
    "  grid = (imarray\n",
    "          .reshape(rows, cols, H, W, C)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(rows*H, cols*H, C))\n",
    "  if pad:\n",
    "    grid = grid[:-pad, :-pad]\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./out/shiftx_aug_argminW_lr0.0002/checkpoint\"\n",
    "sample_dir = \"./out/shiftx_aug_argminW_lr0.0002/sample\"\n",
    "num_samples = 10 # 1 sample per digit\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", num_samples, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# only for jupyter:\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = FLAGS.batch_size # this is a bug, DCGAN.y placeholder is fixed to 64 but what if we want 1 sample?\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=num_samples,\n",
    "    y_dim=FLAGS.y_dim,\n",
    "    z_dim=FLAGS.z_dim,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir,\n",
    "    data_dir=FLAGS.data_dir,\n",
    "    out_dir=FLAGS.out_dir,\n",
    "    max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "if not load_success:\n",
    "    raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing previously trained G\n",
    "# visualize(sess, dcgan, FLAGS, 1, FLAGS.sample_dir)\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "y_one_hot = np.zeros((num_samples, FLAGS.y_dim))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "\n",
    "samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample, dcgan.y: y_one_hot})\n",
    "plt.imshow(samples[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## steerability walk\n",
    "## define the graph\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, FLAGS.z_dim], name='z_sample')\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, FLAGS.y_dim], name='y_sample')\n",
    "\n",
    "## this will go to get_target and then to the loss\n",
    "outputs_orig = dcgan.my_sampler(z_placeholder, y_placeholder)\n",
    "\n",
    "img_size = 28\n",
    "Nsliders = 1\n",
    "target = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "mask = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "alpha = tf.placeholder(tf.float32, shape=None)\n",
    "w = tf.Variable(np.random.uniform(-1, 1, [1, FLAGS.z_dim]), name='walk', dtype=np.float32)\n",
    "\n",
    "z_new = z_placeholder+alpha*w\n",
    "y_new = y_placeholder\n",
    "\n",
    "## this is our transformed\n",
    "transformed_output = dcgan.my_sampler(z_new, y_new)\n",
    "\n",
    "loss = tf.losses.compute_weighted_loss(tf.square(transformed_output-target), weights=mask)\n",
    "lr = 0.005\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss, var_list=tf.trainable_variables(scope='walk'), \n",
    "                                                 name='AdamOpter')\n",
    "\n",
    "## the graph already contains DCGAN and now we want to init the steerability part in it:\n",
    "not_initialized_vars = initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_np(outputs_zs, alpha, show_img=False, show_mask=False):\n",
    "    \n",
    "    mask_fn = np.ones(outputs_zs.shape)\n",
    "    if alpha == 0:\n",
    "        return outputs_zs, mask_fn\n",
    "    \n",
    "    M = np.float32([[1,0,alpha],[0,1,0]])\n",
    "    target_fn = np.zeros(outputs_zs.shape)\n",
    "    mask_out = np.zeros(outputs_zs.shape)\n",
    "    for i in range(outputs_zs.shape[0]):\n",
    "        target_fn[i,:,:,:] = np.expand_dims(cv2.warpAffine(outputs_zs[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "        mask_out[i,:,:,:] = np.expand_dims(cv2.warpAffine(mask_fn[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "\n",
    "    mask_out[np.nonzero(mask_out)] = 1.\n",
    "    assert(np.setdiff1d(mask_out, [0., 1.]).size == 0)\n",
    "        \n",
    "    if show_img:\n",
    "        print('Target image:')\n",
    "#         imshow_unscaled(target_fn)\n",
    "        imshow(target_fn[0,:,:,0], im_size=128)\n",
    "    if show_mask:\n",
    "        print('Target mask:')\n",
    "#         imshow_unscaled(mask_out)\n",
    "        imshow(mask_out[0,:,:,0], im_size=128)\n",
    "\n",
    "    return target_fn, mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p shift_l2_git/images\n",
    "# ! mkdir -p shift_l2_git/output\n",
    "import os\n",
    "output_dir = './out/walk_train_aug/shiftx_l2_git{}'.format(lr)\n",
    "os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'output'), exist_ok=True)\n",
    "saver = tf.train.Saver(tf.trainable_variables(scope=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be train.py\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(output_dir, 'train')),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "logger = logging.getLogger()\n",
    "\n",
    "alpha_list = []\n",
    "loss_vals = []\n",
    "\n",
    "# train\n",
    "train_sample_size = 40000\n",
    "def train(saver):\n",
    "    # init zs\n",
    "    # we want couple of thousands per category, also compatible with batch_size\n",
    "    num_samples = train_sample_size\n",
    "    # sample inputs to feed to placeholders\n",
    "    zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "    # all categories\n",
    "    y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "    ys = np.zeros((num_samples, FLAGS.y_dim))\n",
    "    ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "    Loss_sum = 0;\n",
    "    n_epoch = 1\n",
    "    optim_iter = 0\n",
    "    batch_size = FLAGS.batch_size\n",
    "    loss_values = []\n",
    "    Loss_sum_iter = 0  \n",
    "    alpha_val_max = 5\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            alpha_val = np.random.randint(1, alpha_val_max + 1)  \n",
    "            coin = np.random.uniform(0, 1)\n",
    "            if coin <= 0.5:\n",
    "                alpha_val = -alpha_val\n",
    "\n",
    "            s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "            feed_dict_out = {z_placeholder: zs[s], y_placeholder: ys[s]}\n",
    "            out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "            \n",
    "            target_fn, mask_out = get_target_np(out_zs, alpha_val)#, show_img=True, show_mask=True)\n",
    "\n",
    "            feed_dict = {z_placeholder: zs[s], y_placeholder: ys[s], alpha: alpha_val, target: target_fn, mask: mask_out}\n",
    "            curr_loss, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "            Loss_sum = Loss_sum + curr_loss\n",
    "            Loss_sum_iter = Loss_sum_iter + curr_loss\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            logger.info('T, epc, bst, lss, a: {}, {}, {}, {}, {}'.format(elapsed_time, epoch, batch_start, curr_loss, alpha_val))\n",
    "\n",
    "            alpha_list.append(alpha_val)\n",
    "\n",
    "            if (optim_iter % 2500 == 0) and (optim_iter > 0):\n",
    "                saver.save(sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "            \n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                loss_vals.append(Loss_sum_iter/(100*batch_size))\n",
    "                Loss_sum_iter = 0\n",
    "                print('Loss:', loss_vals)\n",
    "\n",
    "            optim_iter = optim_iter+1\n",
    "            \n",
    "    if optim_iter > 0:\n",
    "        print('average loss with this metric: ', Loss_sum/(optim_iter*batch_size))\n",
    "    saver.save(sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dcgan.saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_vals_x = np.arange(FLAGS.batch_size*100, train_sample_size, FLAGS.batch_size*100)\n",
    "plt.plot(loss_vals_x, loss_vals)\n",
    "plt.xlabel('num samples={}, lr={}'.format(train_sample_size, lr))\n",
    "plt.ylabel('L2')\n",
    "plt.show()\n",
    "print(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: show imgs \n",
    "# Need work:\n",
    "# saver.restore(sess, \"./out/walk_train_aug/shiftx_l2_git0.005/output/model_20000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "a = np.array([-15, -12, -9, -6, -3,  0,  3,  6,  9, 12, 15])\n",
    "\n",
    "zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "ys = np.zeros((num_samples, FLAGS.y_dim))\n",
    "ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "im_targets = []\n",
    "im_transformed = []\n",
    "for i in range(a.shape[0]):\n",
    "    feed_dict_out = {z_placeholder: zs, y_placeholder: ys}\n",
    "    out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "    target_fn, mask_out = get_target_np(out_zs, a[i])#, show_img=True, show_mask=True)\n",
    "    im_targets.append(target_fn)\n",
    "    ## get transformed:\n",
    "    feed_dict = {z_placeholder: zs, y_placeholder: ys, alpha: a[i], target: target_fn, mask: mask_out}\n",
    "    samples = sess.run(transformed_output, feed_dict=feed_dict)\n",
    "    im_transformed.append(samples)\n",
    "#     imshow(imgrid(np.uint8(samples*255), cols=1))\n",
    "\n",
    "ims = []\n",
    "for j in range(FLAGS.y_dim):\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_targets], axis=0))\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_transformed], axis=0))\n",
    "\n",
    "print(a)\n",
    "imshow(imgrid(np.uint8(np.concatenate(ims)*255), cols=a.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_l2_sample = tf.reduce_sum(tf.multiply(tf.square(transformed_output-target), mask), axis=(1,2,3)) \\\n",
    "        / tf.reduce_sum(mask, axis=(1,2,3))\n",
    "\n",
    "loss_l2_trained = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "# import argparse\n",
    "# from utils import *\n",
    "# import graphs\n",
    "# import constants\n",
    "import time\n",
    "import pdb\n",
    "import os\n",
    "# import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 14})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "num_samples = 10000\n",
    "vocab_size = FLAGS.y_dim\n",
    "batch_size = FLAGS.batch_size\n",
    "\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "y_one_hot = np.zeros((len(y), FLAGS.y_dim))\n",
    "y_one_hot[np.arange(len(y)), y] = 1\n",
    "y_one_hot = np.tile(y_one_hot,[num_samples,1])\n",
    "\n",
    "zs = z_sample\n",
    "ys = y_one_hot\n",
    "alphas = a \n",
    "alphas_no_log = a\n",
    "\n",
    "# get alphas list\n",
    "# if type(g) == graphs.ZoomTransform:\n",
    "#     alp = np.linspace(1, opt.max_alpha, opt.num_alphas//2 + 1)\n",
    "#     b = 1/alp\n",
    "#     alphas = np.concatenate((np.delete(b[::-1], -1), alp), axis=0)\n",
    "#     alphas = alphas[::-1]\n",
    "# else:\n",
    "#     alphas = np.linspace(-opt.max_alpha, opt.max_alpha, opt.num_alphas)\n",
    "ylabel = 'L2 Distance'\n",
    "dist_tensor = loss_l2_sample\n",
    "# dist_trained_tensor = loss_l2_trained\n",
    "dist_trained_tensor = loss_l2_sample\n",
    "# dist_info = compute_transform_similarity(...)\n",
    "# plot_similarity(dist_info...)\n",
    "\n",
    "# # if opt.distance == 'l2':\n",
    "# #     ylabel = 'L2 Distance'\n",
    "# #     dist_tensor = g.loss_l2_sample\n",
    "# # elif opt.distance == 'lpips':\n",
    "# #     ylabel = 'Perceptual Distance'\n",
    "# #     dist_tensor = g.loss_lpips_sample\n",
    "# dist_info = compute_transform_similarity(ys, zs, alphas, dist_tensor)\n",
    "# plot_similarity(alphas, dist_info, ylabel, output_dir, 'category_all')\n",
    "# # if opt.category:\n",
    "# #     for c in opt.category:\n",
    "# #         ys = [c] * num_samples\n",
    "# #         ys = one_hot_if_needed(ys, vocab_size)\n",
    "# #         dist_info = compute_transform_similarity(g, ys, zs, alphas,\n",
    "# #                                                  dist_tensor)\n",
    "# #         plot_similarity(alphas, dist_info, ylabel,\n",
    "# #                         output_dir, 'category_{}'.format(c))\n",
    "# # else:\n",
    "# #     categories = np.random.randint(0, vocab_size, size=num_samples)\n",
    "# #     ys = one_hot_if_needed(categories, vocab_size)\n",
    "# #     dist_info = compute_transform_similarity(g, ys, zs, alphas,\n",
    "# #                                              dist_tensor)\n",
    "# #     plot_similarity(alphas, dist_info, ylabel, output_dir,\n",
    "# #                     'category_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_test_alpha_for_graph(alpha, zs_batch):\n",
    "#     alpha = np.log(alpha) # only for zoom\n",
    "    batch_size = zs_batch.shape[0]\n",
    "    slider = alpha * np.ones((batch_size, Nsliders))\n",
    "    return slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = alphas_no_log\n",
    "dist_info = np.empty((num_samples, len(alphas) - 1))\n",
    "dist_trained_info = np.empty((num_samples, len(alphas)))\n",
    "\n",
    "for batch_start in range(0, num_samples, batch_size):\n",
    "    s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "    ys_batch = ys[s]\n",
    "    zs_batch = zs[s]\n",
    "    im_buffer = None # save the first set of images, for consecutive diff\n",
    "    for i, a in enumerate(alphas):\n",
    "        slider = scale_test_alpha_for_graph(a, zs_batch)\n",
    "        input_test = {y_placeholder: ys_batch,\n",
    "                      z_placeholder: zs_batch,\n",
    "                      alpha: slider}\n",
    "        im_transform = sess.run(transformed_output, feed_dict=input_test)\n",
    "#         imshow(imgrid(np.uint8(im_transform*255), cols=1))\n",
    "        if im_buffer is not None:\n",
    "            feed_dict = {\n",
    "                mask: np.ones_like(im_transform),\n",
    "                transformed_output: im_transform,\n",
    "                target: im_buffer\n",
    "            }\n",
    "            # compute consecutive lpips diffs\n",
    "            dist_info[s, i-1] = sess.run(dist_tensor, feed_dict=feed_dict)\n",
    "#             print('consecutive diffs:', sess.run(dist_tensor, feed_dict=feed_dict))\n",
    "        im_buffer = im_transform\n",
    "    \n",
    "        ## now compute the loss of train:\n",
    "        ## already have im_transform, so get target and mask from G(a=0,z)\n",
    "        out_zs = sess.run(outputs_orig, input_test)\n",
    "        target_out, mask_out = get_target_np(out_zs, a)\n",
    "#         imshow(imgrid(np.uint8(im_transform*255), cols=1))\n",
    "#         imshow(imgrid(np.uint8(target_out*255), cols=1))\n",
    "#         imshow(imgrid(np.uint8(mask_out*255), cols=1))\n",
    "        feed_dict = {\n",
    "            mask: mask_out,\n",
    "            transformed_output: im_transform,\n",
    "            target: target_out\n",
    "        }\n",
    "        dist_trained_info[s, i] = sess.run(dist_trained_tensor, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots and saves the computed similarity matrix\n",
    "import os\n",
    "output_dir = './out/plots/'\n",
    "savefile = 'shiftx_aug_argminW_transform_effect_plots'\n",
    "\n",
    "alphas = alphas_no_log\n",
    "\n",
    "xlabel = r'$\\alpha$'\n",
    "if np.min(alphas) > 0:\n",
    "    alphas = np.log(alphas)\n",
    "    xlabel = r'$\\log(\\alpha)$'\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "xaxis = np.mean([alphas[:-1], alphas[1:]], axis=0)\n",
    "mu = np.mean(dist_info, axis=0)\n",
    "sd = np.std(dist_info, axis=0)\n",
    "p = ax.plot(xaxis, mu)\n",
    "ax.fill_between(xaxis, mu-sd, mu+sd, alpha=0.3)\n",
    "xscatter = np.tile(xaxis, (20, 1))\n",
    "yscatter = dist_info[:20] # take the first 20 samples\n",
    "ax.scatter(xscatter, yscatter, marker='.',\n",
    "           edgecolors='none', s=20, color=p[0].get_color())\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "\n",
    "# ax.set_ylim([0, 0.8])\n",
    "ax.set_ylim([0, 0.15])\n",
    "ax.grid(alpha=0.3)\n",
    "# ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "\n",
    "for (x, m, s) in zip(xaxis, mu, sd):\n",
    "    print(\"alpha: {:.2f}, dist {:.2f} +/- {:.2f}\".format(x, m, s))\n",
    "\n",
    "f.savefig(os.path.join(output_dir, savefile + '.png'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)\n",
    "f.savefig(os.path.join(output_dir, savefile + '.pdf'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_trained_joint = np.load(\"dist_trained_info_shiftx_aug_argminGW.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots and saves the computed similarity matrix\n",
    "import os\n",
    "output_dir = './out/plots/'\n",
    "savefile = 'shiftx_aug_argminW_loss_trained_plots'\n",
    "\n",
    "alphas = alphas_no_log\n",
    "\n",
    "xlabel = r'$\\alpha$'\n",
    "if np.min(alphas) > 0:\n",
    "    alphas = np.log(alphas)\n",
    "    xlabel = r'$\\log(\\alpha)$'\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "# xaxis = np.mean([alphas[:-1], alphas[1:]], axis=0)\n",
    "xaxis = np.mean([alphas[:], alphas[:]], axis=0)\n",
    "\n",
    "### For shift no joint\n",
    "mu = np.mean(dist_trained_info, axis=0)\n",
    "sd = np.std(dist_trained_info, axis=0)\n",
    "p = ax.plot(xaxis, mu)\n",
    "ax.fill_between(xaxis, mu-sd, mu+sd, alpha=0.3)\n",
    "xscatter = np.tile(xaxis, (20, 1))\n",
    "yscatter = dist_trained_info[:20] # take the first 20 samples\n",
    "\n",
    "### For shift join\n",
    "mu_j = np.mean(dist_trained_joint, axis=0)\n",
    "sd_j = np.std(dist_trained_joint, axis=0)\n",
    "p_j = ax.plot(xaxis, mu_j)\n",
    "ax.fill_between(xaxis, mu_j-sd_j, mu_j+sd_j, alpha=0.3)\n",
    "xscatter_j = np.tile(xaxis, (20,1))\n",
    "yscatter_j = dist_trained_joint[:20]\n",
    "\n",
    "ax.scatter(xscatter, yscatter, marker='.',\n",
    "           edgecolors='none', s=20, color=p[0].get_color())\n",
    "\n",
    "ax.scatter(xscatter_j, yscatter_j, marker='*', edgecolors='none', s=20, color=p_j[0].get_color())\n",
    "\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "\n",
    "# ax.set_ylim([0, 0.8])\n",
    "ax.set_ylim([0, 0.3])\n",
    "ax.grid(alpha=0.3)\n",
    "# ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "\n",
    "for (x, m, s) in zip(xaxis, mu, sd):\n",
    "    print(\"alpha: {:.2f}, dist {:.2f} +/- {:.2f}\".format(x, m, s))\n",
    "\n",
    "f.savefig(os.path.join(output_dir, savefile + '.png'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)\n",
    "f.savefig(os.path.join(output_dir, savefile + '.pdf'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
