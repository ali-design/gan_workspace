{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model_argminGW2_shiftx import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "from ops import batch_norm\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, im_size=256, format='png', jpeg_fallback=True, filename=None):\n",
    "  if a.dtype != np.uint8:\n",
    "      a = a*255\n",
    "  a = np.asarray(a, dtype=np.uint8)\n",
    "  a = cv2.resize(a, (a.shape[1], a.shape[0]))\n",
    "\n",
    "  str_file = io.BytesIO()\n",
    "  PIL.Image.fromarray(a).save(str_file, format)\n",
    "  im_data = str_file.getvalue()\n",
    "  try:\n",
    "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    if filename:\n",
    "        size = (a.shape[1]//2, a.shape[0]//2)\n",
    "        im = PIL.Image.fromarray(a)\n",
    "        im.thumbnail(size,PIL.Image.ANTIALIAS)\n",
    "        im.save('{}.{}'.format(filename, format))\n",
    "        \n",
    "  except IOError:\n",
    "    if jpeg_fallback and format != 'jpeg':\n",
    "      print ('Warning: image was too large to display in format \"{}\"; '\n",
    "             'trying jpeg instead.').format(format)\n",
    "      return imshow(a, format='jpeg')\n",
    "    else:\n",
    "      raise\n",
    "  return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgrid(imarray, cols=5, pad=1):\n",
    "  if imarray.dtype != np.uint8:\n",
    "    raise ValueError('imgrid input imarray must be uint8')\n",
    "  pad = int(pad)\n",
    "  assert pad >= 0\n",
    "  cols = int(cols)\n",
    "  assert cols >= 1\n",
    "  N, H, W, C = imarray.shape\n",
    "  rows = int(np.ceil(N / float(cols)))\n",
    "  batch_pad = rows * cols - N\n",
    "  assert batch_pad >= 0\n",
    "  post_pad = [batch_pad, pad, pad, 0]\n",
    "  pad_arg = [[0, p] for p in post_pad]\n",
    "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n",
    "  H += pad\n",
    "  W += pad\n",
    "  grid = (imarray\n",
    "          .reshape(rows, cols, H, W, C)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(rows*H, cols*H, C))\n",
    "  if pad:\n",
    "    grid = grid[:-pad, :-pad]\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11554717696",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7020b72c7e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 11554717696"
     ]
    }
   ],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'shiftx_aug_argminGW_lr0.0005'\n",
    "checkpoint_dir = os.path.join('./out',file_name,'checkpoint' )\n",
    "sample_dir = os.path.join('./out',file_name,'sample' )\n",
    "num_samples = 10 # 1 sample per digit\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", num_samples, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_boolean(\"aug\", False, \"True for enabling transformation augmentation\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# only for jupyter:\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=num_samples,\n",
    "    y_dim=FLAGS.y_dim,\n",
    "    z_dim=FLAGS.z_dim,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    aug=FLAGS.aug,    \n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir,\n",
    "    data_dir=FLAGS.data_dir,\n",
    "    out_dir=FLAGS.out_dir,\n",
    "    max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "if not load_success:\n",
    "    raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(sess, dcgan, FLAGS, 1, FLAGS.sample_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10 # 1 sample per digit\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "# y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "y_one_hot = np.zeros((num_samples, FLAGS.y_dim))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "\n",
    "im_targets = []\n",
    "im_transformed = []\n",
    "\n",
    "a = np.array([-8, -6, -5, -4, -2,  0,  2,  4,  5, 6, 8])\n",
    "# a = np.array([-15, -12, -9, -6, -3,  0,  3,  6,  9, 12, 15])\n",
    "alpha = np.tile(a, [num_samples, 1])\n",
    "\n",
    "for i in range(alpha.shape[1]):\n",
    "    # get G and then targets:\n",
    "    samples = sess.run(dcgan.sampler, feed_dict = {dcgan.z: z_sample, dcgan.y: y_one_hot})    \n",
    "    targets, masks = dcgan.get_target_np(samples, np.expand_dims(alpha[:,i], axis=1))\n",
    "    im_targets.append(targets)\n",
    "    # get transformed:\n",
    "    samples = sess.run(dcgan.sampler_new, feed_dict = {dcgan.z: z_sample, \n",
    "                                                       dcgan.y: y_one_hot, \n",
    "                                                       dcgan.alpha: np.expand_dims(alpha[:,i],axis=1)})\n",
    "    im_transformed.append(samples)\n",
    "# imshow(imgrid(np.uint8(samples*255), cols=1))\n",
    "\n",
    "ims = []\n",
    "for j in range(FLAGS.y_dim):\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_targets], axis=0))\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_transformed], axis=0))\n",
    "\n",
    "print(alpha[0])\n",
    "imshow(imgrid(np.uint8(np.concatenate(ims)*255), cols=alpha.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_l2_sample = tf.reduce_sum(tf.multiply(tf.square(\n",
    "    dcgan.sampler_new-dcgan.target), dcgan.mask), axis=(1,2,3)) \\\n",
    "        / tf.reduce_sum(dcgan.mask, axis=(1,2,3))\n",
    "\n",
    "loss_l2_trained = tf.losses.compute_weighted_loss(tf.square(dcgan.sampler_new - dcgan.target), weights=dcgan.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "# import argparse\n",
    "# from utils import *\n",
    "# import graphs\n",
    "# import constants\n",
    "import time\n",
    "import pdb\n",
    "import os\n",
    "# import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 14})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "num_samples = 10000\n",
    "vocab_size = FLAGS.y_dim\n",
    "batch_size = FLAGS.batch_size\n",
    "\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "y_one_hot = np.zeros((len(y), FLAGS.y_dim))\n",
    "y_one_hot[np.arange(len(y)), y] = 1\n",
    "y_one_hot = np.tile(y_one_hot,[num_samples,1])\n",
    "\n",
    "zs = z_sample\n",
    "ys = y_one_hot\n",
    "alphas = alpha \n",
    "alphas_no_log = alpha\n",
    "# get alphas list\n",
    "# if type(g) == graphs.ZoomTransform:\n",
    "#     alp = np.linspace(1, opt.max_alpha, opt.num_alphas//2 + 1)\n",
    "#     b = 1/alp\n",
    "#     alphas = np.concatenate((np.delete(b[::-1], -1), alp), axis=0)\n",
    "#     alphas = alphas[::-1]\n",
    "# else:\n",
    "#     alphas = np.linspace(-opt.max_alpha, opt.max_alpha, opt.num_alphas)\n",
    "ylabel = 'L2 Distance'\n",
    "dist_tensor = loss_l2_sample\n",
    "dist_trained_tensor = loss_l2_trained\n",
    "# dist_trained_tensor = loss_l2_sample\n",
    "# dist_info = compute_transform_similarity(...)\n",
    "# plot_similarity(dist_info...)\n",
    "\n",
    "# # if opt.distance == 'l2':\n",
    "# #     ylabel = 'L2 Distance'\n",
    "# #     dist_tensor = g.loss_l2_sample\n",
    "# # elif opt.distance == 'lpips':\n",
    "# #     ylabel = 'Perceptual Distance'\n",
    "# #     dist_tensor = g.loss_lpips_sample\n",
    "# dist_info = compute_transform_similarity(ys, zs, alphas, dist_tensor)\n",
    "# plot_similarity(alphas, dist_info, ylabel, output_dir, 'category_all')\n",
    "# # if opt.category:\n",
    "# #     for c in opt.category:\n",
    "# #         ys = [c] * num_samples\n",
    "# #         ys = one_hot_if_needed(ys, vocab_size)\n",
    "# #         dist_info = compute_transform_similarity(g, ys, zs, alphas,\n",
    "# #                                                  dist_tensor)\n",
    "# #         plot_similarity(alphas, dist_info, ylabel,\n",
    "# #                         output_dir, 'category_{}'.format(c))\n",
    "# # else:\n",
    "# #     categories = np.random.randint(0, vocab_size, size=num_samples)\n",
    "# #     ys = one_hot_if_needed(categories, vocab_size)\n",
    "# #     dist_info = compute_transform_similarity(g, ys, zs, alphas,\n",
    "# #                                              dist_tensor)\n",
    "# #     plot_similarity(alphas, dist_info, ylabel, output_dir,\n",
    "# #                     'category_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_test_alpha_for_graph(alpha, zs_batch):\n",
    "#     alpha = np.log(alpha) # only for zoom\n",
    "    batch_size = zs_batch.shape[0]\n",
    "    slider = alpha * np.ones((batch_size, dcgan.Nsliders))\n",
    "    return slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_info = np.empty((num_samples, len(alphas) - 1))\n",
    "dist_info = np.empty((num_samples, len(alphas[0,:]) - 1))\n",
    "dist_trained_info = np.empty((num_samples, len(alphas[0,:])))\n",
    "\n",
    "for batch_start in range(0, num_samples, batch_size):\n",
    "    s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "    ys_batch = ys[s]\n",
    "    zs_batch = zs[s]\n",
    "    im_buffer = None # save the first set of images, for consecutive diff\n",
    "    for i, a in enumerate(alphas[0]):\n",
    "        slider = scale_test_alpha_for_graph(a, zs_batch)\n",
    "        input_test = {dcgan.y: ys_batch,\n",
    "                      dcgan.z: zs_batch,\n",
    "                      dcgan.alpha: slider}\n",
    "        im_transform = sess.run(dcgan.sampler_new, feed_dict=input_test)\n",
    "#         imshow(imgrid(np.uint8(im_transform*255), cols=1))\n",
    "        if im_buffer is not None:\n",
    "            feed_dict = {\n",
    "                dcgan.mask: np.ones_like(im_transform),\n",
    "                dcgan.sampler_new: im_transform,\n",
    "                dcgan.target: im_buffer\n",
    "            }\n",
    "            # compute consecutive lpips diffs\n",
    "            dist_info[s, i-1] = sess.run(dist_tensor, feed_dict=feed_dict)\n",
    "#             print('consecutive diffs:', sess.run(dist_tensor, feed_dict=feed_dict))\n",
    "        im_buffer = im_transform\n",
    "    \n",
    "        ## now compute the loss of train:\n",
    "        ## already have im_transform, so get target and mask from G(a=0,z)\n",
    "        out_zs = sess.run(dcgan.sampler, feed_dict=input_test)\n",
    "        target_out, mask_out = dcgan.get_target_np(out_zs, slider)\n",
    "#         imshow(imgrid(np.uint8(im_transform*255), cols=1))\n",
    "#         imshow(imgrid(np.uint8(target_out*255), cols=1))\n",
    "#         imshow(imgrid(np.uint8(mask_out*255), cols=1))\n",
    "        feed_dict = {\n",
    "            dcgan.mask: mask_out,\n",
    "            dcgan.sampler_new: im_transform,\n",
    "            dcgan.target: target_out\n",
    "        }\n",
    "        dist_trained_info[s, i] = sess.run(dist_trained_tensor, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots and saves the computed similarity matrix\n",
    "output_dir = './out/plots/'\n",
    "savefile = file_name+'transform_effect_plots'\n",
    "\n",
    "alphas = alphas_no_log\n",
    "\n",
    "xlabel = r'$\\alpha$'\n",
    "if np.min(alphas) > 0:\n",
    "    alphas = np.log(alphas)\n",
    "    xlabel = r'$\\log(\\alpha)$'\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "# xaxis = np.mean([alphas[:-1], alphas[1:]], axis=0)\n",
    "xaxis = np.mean([alphas[0,:-1], alphas[0,1:]], axis=0)\n",
    "mu = np.mean(dist_info, axis=0)\n",
    "sd = np.std(dist_info, axis=0)\n",
    "p = ax.plot(xaxis, mu)\n",
    "ax.fill_between(xaxis, mu-sd, mu+sd, alpha=0.3)\n",
    "xscatter = np.tile(xaxis, (20, 1))\n",
    "yscatter = dist_info[:20] # take the first 20 samples\n",
    "ax.scatter(xscatter, yscatter, marker='.',\n",
    "           edgecolors='none', s=20, color=p[0].get_color())\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "\n",
    "# ax.set_ylim([0, 0.8])\n",
    "ax.set_ylim([0, 0.15])\n",
    "ax.grid(alpha=0.3)\n",
    "# ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "ax.set_xlim([np.min(alphas[0,:]), np.max(alphas[0,:])])\n",
    "\n",
    "for (x, m, s) in zip(xaxis, mu, sd):\n",
    "    print(\"alpha: {:.2f}, dist {:.2f} +/- {:.2f}\".format(x, m, s))\n",
    "\n",
    "f.savefig(os.path.join(output_dir, savefile + '.png'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)\n",
    "f.savefig(os.path.join(output_dir, savefile + '.pdf'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots and saves the computed similarity matrix\n",
    "import os\n",
    "output_dir = './out/plots/'\n",
    "savefile_loss = file_name+'loss_trained_plots'\n",
    "\n",
    "alphas = alphas_no_log\n",
    "\n",
    "xlabel = r'$\\alpha$'\n",
    "if np.min(alphas) > 0:\n",
    "    alphas = np.log(alphas)\n",
    "    xlabel = r'$\\log(\\alpha)$'\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "# xaxis = np.mean([alphas[:-1], alphas[1:]], axis=0)\n",
    "xaxis = np.mean([alphas[0,:], alphas[0,:]], axis=0)\n",
    "mu = np.mean(dist_trained_info, axis=0)\n",
    "sd = np.std(dist_trained_info, axis=0)\n",
    "p = ax.plot(xaxis, mu)\n",
    "ax.fill_between(xaxis, mu-sd, mu+sd, alpha=0.3)\n",
    "xscatter = np.tile(xaxis, (20, 1))\n",
    "yscatter = dist_trained_info[:20] # take the first 20 samples\n",
    "ax.scatter(xscatter, yscatter, marker='.',\n",
    "           edgecolors='none', s=20, color=p[0].get_color())\n",
    "ax.set_xlabel(xlabel)\n",
    "ax.set_ylabel(ylabel)\n",
    "\n",
    "# ax.set_ylim([0, 0.8])\n",
    "ax.set_ylim([0, 0.3])\n",
    "ax.grid(alpha=0.3)\n",
    "# ax.set_xlim([np.min(alphas), np.max(alphas)])\n",
    "ax.set_xlim([np.min(alphas[0,:]), np.max(alphas[0,:])])\n",
    "\n",
    "for (x, m, s) in zip(xaxis, mu, sd):\n",
    "    print(\"alpha: {:.2f}, dist {:.2f} +/- {:.2f}\".format(x, m, s))\n",
    "\n",
    "f.savefig(os.path.join(output_dir, savefile_loss + '.png'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)\n",
    "f.savefig(os.path.join(output_dir, savefile_loss + '.pdf'),\n",
    "          bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(savefile_loss+'.npy', dist_trained_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
