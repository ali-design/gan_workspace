{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model_steer2_zoom import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, im_size=256, format='png', jpeg_fallback=True, filename=None):\n",
    "  if a.dtype != np.uint8:\n",
    "      a = a*255\n",
    "  a = np.asarray(a, dtype=np.uint8)\n",
    "  a = cv2.resize(a, (a.shape[1], a.shape[0]))\n",
    "\n",
    "  str_file = io.BytesIO()\n",
    "  PIL.Image.fromarray(a).save(str_file, format)\n",
    "  im_data = str_file.getvalue()\n",
    "  try:\n",
    "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    if filename:\n",
    "        size = (a.shape[1]//2, a.shape[0]//2)\n",
    "        im = PIL.Image.fromarray(a)\n",
    "        im.thumbnail(size,PIL.Image.ANTIALIAS)\n",
    "        im.save('{}.{}'.format(filename, format))\n",
    "        \n",
    "  except IOError:\n",
    "    if jpeg_fallback and format != 'jpeg':\n",
    "      print ('Warning: image was too large to display in format \"{}\"; '\n",
    "             'trying jpeg instead.').format(format)\n",
    "      return imshow(a, format='jpeg')\n",
    "    else:\n",
    "      raise\n",
    "  return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgrid(imarray, cols=5, pad=1):\n",
    "  if imarray.dtype != np.uint8:\n",
    "    raise ValueError('imgrid input imarray must be uint8')\n",
    "  pad = int(pad)\n",
    "  assert pad >= 0\n",
    "  cols = int(cols)\n",
    "  assert cols >= 1\n",
    "  N, H, W, C = imarray.shape\n",
    "  rows = int(np.ceil(N / float(cols)))\n",
    "  batch_pad = rows * cols - N\n",
    "  assert batch_pad >= 0\n",
    "  post_pad = [batch_pad, pad, pad, 0]\n",
    "  pad_arg = [[0, p] for p in post_pad]\n",
    "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n",
    "  H += pad\n",
    "  W += pad\n",
    "  grid = (imarray\n",
    "          .reshape(rows, cols, H, W, C)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(rows*H, cols*H, C))\n",
    "  if pad:\n",
    "    grid = grid[:-pad, :-pad]\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need not to set aug=True but need to load pretrained G that is trained on augmented data\n",
    "checkpoint_dir = \"./out/zoom_origG_aug_inplace_mnist/checkpoint\" \n",
    "sample_dir = \"./out/zoom_origG_aug_inplace_mnist/sample\"\n",
    "num_samples = 10 # 1 sample per digit\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", num_samples, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_boolean(\"aug\", False, \"True for enabling transformation augmentation\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# only for jupyter:\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = FLAGS.batch_size # this is a bug, DCGAN.y placeholder is fixed to 64 but what if we want 1 sample?\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=num_samples,\n",
    "    y_dim=FLAGS.y_dim,\n",
    "    z_dim=FLAGS.z_dim,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    aug=FLAGS.aug,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir,\n",
    "    data_dir=FLAGS.data_dir,\n",
    "    out_dir=FLAGS.out_dir,\n",
    "    max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "if not load_success:\n",
    "    raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing previously trained G\n",
    "# visualize(sess, dcgan, FLAGS, 1, FLAGS.sample_dir)\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "y_one_hot = np.zeros((num_samples, FLAGS.y_dim))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "\n",
    "samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample, dcgan.y: y_one_hot})\n",
    "plt.imshow(samples[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## steerability walk\n",
    "## define the graph\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, FLAGS.z_dim], name='z_sample')\n",
    "y_placeholder = tf.placeholder(tf.float32, [None, FLAGS.y_dim], name='y_sample')\n",
    "\n",
    "## this will go to get_target and then to the loss\n",
    "outputs_orig = dcgan.my_sampler(z_placeholder, y_placeholder)\n",
    "\n",
    "img_size = 28\n",
    "Nsliders = 1\n",
    "target = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "mask = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "alpha = tf.placeholder(tf.float32, shape=None)\n",
    "w = tf.Variable(np.random.uniform(-1, 1, [1, FLAGS.z_dim]), name='walk', dtype=np.float32)\n",
    "\n",
    "z_new = z_placeholder+alpha*w\n",
    "y_new = y_placeholder\n",
    "\n",
    "## this is our transformed\n",
    "transformed_output = dcgan.my_sampler(z_new, y_new)\n",
    "\n",
    "loss = tf.losses.compute_weighted_loss(tf.square(transformed_output-target), weights=mask)\n",
    "lr = 0.005\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss, var_list=tf.trainable_variables(scope='walk'), \n",
    "                                                 name='AdamOpter')\n",
    "\n",
    "## the graph already contains DCGAN and now we want to init the steerability part in it:\n",
    "not_initialized_vars = initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_target_np(outputs_zs, alpha, show_img=False, show_mask=False):\n",
    "    \n",
    "#     mask_fn = np.ones(outputs_zs.shape)\n",
    "#     if alpha == 0:\n",
    "#         return outputs_zs, mask_fn\n",
    "    \n",
    "#     M = np.float32([[1,0,alpha],[0,1,0]])\n",
    "#     target_fn = np.zeros(outputs_zs.shape)\n",
    "#     mask_out = np.zeros(outputs_zs.shape)\n",
    "#     for i in range(outputs_zs.shape[0]):\n",
    "#         target_fn[i,:,:,:] = np.expand_dims(cv2.warpAffine(outputs_zs[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "#         mask_out[i,:,:,:] = np.expand_dims(cv2.warpAffine(mask_fn[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "\n",
    "#     mask_out[np.nonzero(mask_out)] = 1.\n",
    "#     assert(np.setdiff1d(mask_out, [0., 1.]).size == 0)\n",
    "        \n",
    "#     if show_img:\n",
    "#         print('Target image:')\n",
    "# #         imshow_unscaled(target_fn)\n",
    "#         imshow(target_fn[0,:,:,0], im_size=128)\n",
    "#     if show_mask:\n",
    "#         print('Target mask:')\n",
    "# #         imshow_unscaled(mask_out)\n",
    "#         imshow(mask_out[0,:,:,0], im_size=128)\n",
    "\n",
    "#     return target_fn, mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p shift_l2_git/images\n",
    "# ! mkdir -p shift_l2_git/output\n",
    "import os\n",
    "output_dir = './out/walk_train_aug/shiftx_l2_git{}'.format(lr)\n",
    "os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'output'), exist_ok=True)\n",
    "saver = tf.train.Saver(tf.trainable_variables(scope=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be train.py\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format(output_dir, 'train')),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "logger = logging.getLogger()\n",
    "\n",
    "alpha_list = []\n",
    "loss_vals = []\n",
    "\n",
    "# train\n",
    "train_sample_size = 20000\n",
    "def train(saver):\n",
    "    # init zs\n",
    "    # we want couple of thousands per category, also compatible with batch_size\n",
    "    num_samples = train_sample_size\n",
    "    # sample inputs to feed to placeholders\n",
    "    zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "    # all categories\n",
    "    y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "    ys = np.zeros((num_samples, FLAGS.y_dim))\n",
    "    ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "    Loss_sum = 0;\n",
    "    n_epoch = 1\n",
    "    optim_iter = 0\n",
    "    batch_size = FLAGS.batch_size\n",
    "    loss_values = []\n",
    "    Loss_sum_iter = 0  \n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            alpha_val = np.random.randint(1, 6)  \n",
    "            coin = np.random.uniform(0, 1)\n",
    "            if coin <= 0.5:\n",
    "                alpha_val = -alpha_val\n",
    "\n",
    "            s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "            feed_dict_out = {z_placeholder: zs[s], y_placeholder: ys[s]}\n",
    "            out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "            \n",
    "            target_fn, mask_out = dcgan.get_target_np(out_zs, alpha_val)#, show_img=True, show_mask=True)\n",
    "\n",
    "            feed_dict = {z_placeholder: zs[s], y_placeholder: ys[s], alpha: alpha_val, target: target_fn, mask: mask_out}\n",
    "            curr_loss, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "\n",
    "            Loss_sum = Loss_sum + curr_loss\n",
    "            Loss_sum_iter = Loss_sum_iter + curr_loss\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            logger.info('T, epc, bst, lss, a: {}, {}, {}, {}, {}'.format(elapsed_time, epoch, batch_start, curr_loss, alpha_val))\n",
    "\n",
    "            alpha_list.append(alpha_val)\n",
    "\n",
    "            if (optim_iter % 2500 == 0) and (optim_iter > 0):\n",
    "                saver.save(style_sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "            \n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                loss_vals.append(Loss_sum_iter/(100*batch_size))\n",
    "                Loss_sum_iter = 0\n",
    "                print('Loss:', loss_vals)\n",
    "\n",
    "            optim_iter = optim_iter+1\n",
    "            \n",
    "    if optim_iter > 0:\n",
    "        print('average loss with this metric: ', Loss_sum/(optim_iter*batch_size))\n",
    "    saver.save(sess, '{}/{}/model_{}.ckpt'.format(output_dir, 'output', optim_iter*batch_size), write_meta_graph=False, write_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dcgan.saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_vals_x = np.arange(FLAGS.batch_size*100, train_sample_size, FLAGS.batch_size*100)\n",
    "plt.plot(loss_vals_x, loss_vals)\n",
    "plt.xlabel('num samples={}, lr={}'.format(train_sample_size, lr))\n",
    "plt.ylabel('L2')\n",
    "plt.show()\n",
    "print(loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: show imgs \n",
    "# Need work:\n",
    "# saver.restore(sess, \"./out/walk_train_aug/shiftx_l2_git0.005/output/model_20000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "lower_bound = -8\n",
    "a = np.arange(lower_bound, -lower_bound+1, 1)\n",
    "\n",
    "zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "ys = np.zeros((num_samples, FLAGS.y_dim))\n",
    "ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "im_targets = []\n",
    "im_transformed = []\n",
    "for i in range(a.shape[0]):\n",
    "    feed_dict_out = {z_placeholder: zs, y_placeholder: ys}\n",
    "    out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "    target_fn, mask_out = get_target_np(out_zs, a[i])#, show_img=True, show_mask=True)\n",
    "    im_targets.append(target_fn)\n",
    "    ## get transformed:\n",
    "    feed_dict = {z_placeholder: zs, y_placeholder: ys, alpha: a[i], target: target_fn, mask: mask_out}\n",
    "    samples = sess.run(transformed_output, feed_dict=feed_dict)\n",
    "    im_transformed.append(samples)\n",
    "#     imshow(imgrid(np.uint8(samples*255), cols=1))\n",
    "\n",
    "ims = []\n",
    "for j in range(FLAGS.y_dim):\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_targets], axis=0))\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_transformed], axis=0))\n",
    "\n",
    "print(a)\n",
    "imshow(imgrid(np.uint8(np.concatenate(ims)*255), cols=a.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
