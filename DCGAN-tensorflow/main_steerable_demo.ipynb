{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string(\"transform_type\", \"zoom\", \"The name of dataset [zoom, shiftx, shifty, rot2d]\")\n",
    "flags.DEFINE_boolean(\"steer\", False, \"True for traning argminGW, False for training vanilla G\")\n",
    "flags.DEFINE_boolean(\"aug\", False, \"True for enabling transformation augmentation\")\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "# flags.DEFINE_integer(\"input_height\", 108, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [28]\")\n",
    "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "# flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [28]\")\n",
    "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "  FLAGS.train = True\n",
    "   \n",
    "#   if FLAGS.steer:\n",
    "#     print('Training with steerable G -> loading model_argminGW2_{} ...'.format(FLAGS.transform_type))\n",
    "#     DCGAN = getattr(importlib.import_module('model_argminGW2_{}'.format(FLAGS.transform_type)), 'DCGAN')\n",
    "#   else:\n",
    "#     print('Training vanilla G -> loading model_vanilla_{} ...'.format(FLAGS.transform_type))\n",
    "#     DCGAN = getattr(importlib.import_module('model_vanilla_{}'.format(FLAGS.transform_type)), 'DCGAN')\n",
    "\n",
    "  print('Training with steerable G for {} transformation ...'.format(FLAGS.transform_type))\n",
    "  if FLAGS.transform_type == 'zoom':\n",
    "    if FLAGS.steer:\n",
    "      from model_argminGW2_zoom import DCGAN\n",
    "    else: \n",
    "      from model_vanilla_zoom import DCGAN\n",
    "        \n",
    "  if FLAGS.transform_type == 'shiftx':\n",
    "    if FLAGS.steer:\n",
    "      from model_argminGW2_shiftx import DCGAN\n",
    "    else: \n",
    "      from model_vanilla_shiftx import DCGAN\n",
    "    \n",
    "  if FLAGS.transform_type == 'shifty':\n",
    "    if FLAGS.steer:\n",
    "      from model_argminGW2_shifty import DCGAN\n",
    "    else: \n",
    "      from model_vanilla_shifty import DCGAN\n",
    "    \n",
    "  if FLAGS.transform_type == 'rot2d':\n",
    "    if FLAGS.steer:\n",
    "      from model_argminGW2_rot2d import DCGAN\n",
    "    else: \n",
    "      from model_vanilla_rot2d import DCGAN\n",
    "    \n",
    "  augment_flag_str = 'NoAug'\n",
    "  if FLAGS.aug:\n",
    "    augment_flag_str = 'aug'\n",
    "  \n",
    "  steer_flag_str = 'vanilla'\n",
    "  if FLAGS.steer:\n",
    "    steer_flag_str = 'argminGW'\n",
    "  else:\n",
    "    if FLAGS.aug:\n",
    "        steer_flag_str = 'argminW'\n",
    "\n",
    "  if FLAGS.out_name:\n",
    "    FLAGS.out_name = expand_path(FLAGS.out_name)\n",
    "  else:\n",
    "    FLAGS.out_name = FLAGS.transform_type + '_' + augment_flag_str + '_' + steer_flag_str + '_lr' + str(FLAGS.learning_rate)\n",
    "  print('Results will be saved in {}'.format(FLAGS.out_name))\n",
    "\n",
    "  # expand user name and environment variables\n",
    "  FLAGS.data_dir = expand_path(FLAGS.data_dir)\n",
    "  FLAGS.out_dir = expand_path(FLAGS.out_dir)\n",
    "#   FLAGS.out_name = expand_path(FLAGS.out_name)\n",
    "  FLAGS.checkpoint_dir = expand_path(FLAGS.checkpoint_dir)\n",
    "  FLAGS.sample_dir = expand_path(FLAGS.sample_dir)\n",
    "\n",
    "  if FLAGS.output_height is None: FLAGS.output_height = FLAGS.input_height\n",
    "  if FLAGS.input_width is None: FLAGS.input_width = FLAGS.input_height\n",
    "  if FLAGS.output_width is None: FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "  # output folders\n",
    "  if FLAGS.out_name == \"\":\n",
    "      FLAGS.out_name = '{} - {} - {}'.format(timestamp(), FLAGS.data_dir.split('/')[-1], FLAGS.dataset) # penultimate folder of path\n",
    "      if FLAGS.train:\n",
    "        FLAGS.out_name += ' - x{}.z{}.{}.y{}.b{}'.format(FLAGS.input_width, FLAGS.z_dim, FLAGS.z_dist, FLAGS.output_width, FLAGS.batch_size)\n",
    "\n",
    "  FLAGS.out_dir = os.path.join(FLAGS.out_dir, FLAGS.out_name)\n",
    "  FLAGS.checkpoint_dir = os.path.join(FLAGS.out_dir, FLAGS.checkpoint_dir)\n",
    "  FLAGS.sample_dir = os.path.join(FLAGS.out_dir, FLAGS.sample_dir)\n",
    "\n",
    "  if not os.path.exists(FLAGS.checkpoint_dir): os.makedirs(FLAGS.checkpoint_dir)\n",
    "  if not os.path.exists(FLAGS.sample_dir): os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "  with open(os.path.join(FLAGS.out_dir, 'FLAGS.json'), 'w') as f:\n",
    "    flags_dict = {k:FLAGS[k].value for k in FLAGS}\n",
    "    json.dump(flags_dict, f, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "  \n",
    "\n",
    "  #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "  run_config = tf.ConfigProto()\n",
    "  run_config.gpu_options.allow_growth=True\n",
    "\n",
    "  with tf.Session(config=run_config) as sess:\n",
    "    if FLAGS.dataset == 'mnist':\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          input_width=FLAGS.input_width,\n",
    "          input_height=FLAGS.input_height,\n",
    "          output_width=FLAGS.output_width,\n",
    "          output_height=FLAGS.output_height,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          y_dim=10,\n",
    "          z_dim=FLAGS.z_dim,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          aug=FLAGS.aug,\n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          data_dir=FLAGS.data_dir,\n",
    "          out_dir=FLAGS.out_dir,\n",
    "          max_to_keep=FLAGS.max_to_keep)\n",
    "    else:\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          input_width=FLAGS.input_width,\n",
    "          input_height=FLAGS.input_height,\n",
    "          output_width=FLAGS.output_width,\n",
    "          output_height=FLAGS.output_height,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          z_dim=FLAGS.z_dim,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          aug=FLAGS.aug,\n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          data_dir=FLAGS.data_dir,\n",
    "          out_dir=FLAGS.out_dir,\n",
    "          max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "    show_all_variables()\n",
    "\n",
    "    if FLAGS.train:\n",
    "      dcgan.train(FLAGS)\n",
    "    else:\n",
    "      load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "      if not load_success:\n",
    "        raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)\n",
    "\n",
    "\n",
    "    # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
    "    #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
    "    #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
    "    #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
    "    #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
    "\n",
    "    # Below is codes for visualization\n",
    "      if FLAGS.export:\n",
    "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'export_b'+str(FLAGS.batch_size))\n",
    "        dcgan.save(export_dir, load_counter, ckpt=True, frozen=False)\n",
    "\n",
    "      if FLAGS.freeze:\n",
    "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'frozen_b'+str(FLAGS.batch_size))\n",
    "        dcgan.save(export_dir, load_counter, ckpt=False, frozen=True)\n",
    "\n",
    "      if FLAGS.visualize:\n",
    "        OPTION = 1\n",
    "        visualize(sess, dcgan, FLAGS, OPTION, FLAGS.sample_dir)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'G_img_sum': <absl.flags._flag.BooleanFlag object at 0x7f7cd0474c88>,\n",
      " 'aug': <absl.flags._flag.BooleanFlag object at 0x7f7c788bb780>,\n",
      " 'batch_size': <absl.flags._flag.Flag object at 0x7f7cd046cf28>,\n",
      " 'beta1': <absl.flags._flag.Flag object at 0x7f7cd046ce10>,\n",
      " 'checkpoint_dir': <absl.flags._flag.Flag object at 0x7f7cd04745c0>,\n",
      " 'ckpt_freq': <absl.flags._flag.Flag object at 0x7f7cd04749b0>,\n",
      " 'crop': <absl.flags._flag.BooleanFlag object at 0x7f7cd04747b8>,\n",
      " 'data_dir': <absl.flags._flag.Flag object at 0x7f7cd0474400>,\n",
      " 'dataset': <absl.flags._flag.Flag object at 0x7f7cd0474278>,\n",
      " 'epoch': <absl.flags._flag.Flag object at 0x7f7cf22175f8>,\n",
      " 'export': <absl.flags._flag.BooleanFlag object at 0x7f7cd0474898>,\n",
      " 'freeze': <absl.flags._flag.BooleanFlag object at 0x7f7cd0474908>,\n",
      " 'h': <tensorflow.python.platform.app._HelpFlag object at 0x7f7d0c52f2b0>,\n",
      " 'help': <tensorflow.python.platform.app._HelpFlag object at 0x7f7d0c52f2b0>,\n",
      " 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x7f7d0c52f1d0>,\n",
      " 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x7f7d0c52f080>,\n",
      " 'input_fname_pattern': <absl.flags._flag.Flag object at 0x7f7cd0474358>,\n",
      " 'input_height': <absl.flags._flag.Flag object at 0x7f7cd0474048>,\n",
      " 'input_width': <absl.flags._flag.Flag object at 0x7f7cd04740b8>,\n",
      " 'learning_rate': <absl.flags._flag.Flag object at 0x7f7cd046ce80>,\n",
      " 'max_to_keep': <absl.flags._flag.Flag object at 0x7f7cd04748d0>,\n",
      " 'out_dir': <absl.flags._flag.Flag object at 0x7f7cd04744a8>,\n",
      " 'out_name': <absl.flags._flag.Flag object at 0x7f7cd04744e0>,\n",
      " 'output_height': <absl.flags._flag.Flag object at 0x7f7cd0474160>,\n",
      " 'output_width': <absl.flags._flag.Flag object at 0x7f7cd0474240>,\n",
      " 'sample_dir': <absl.flags._flag.Flag object at 0x7f7cd0474668>,\n",
      " 'sample_freq': <absl.flags._flag.Flag object at 0x7f7cd0474940>,\n",
      " 'steer': <absl.flags._flag.BooleanFlag object at 0x7f7d0c4c41d0>,\n",
      " 'train': <absl.flags._flag.BooleanFlag object at 0x7f7cd0474748>,\n",
      " 'train_size': <absl.flags._flag.Flag object at 0x7f7cd046cef0>,\n",
      " 'transform_type': <absl.flags._flag.Flag object at 0x7f7d0c52ff28>,\n",
      " 'visualize': <absl.flags._flag.BooleanFlag object at 0x7f7cd0474828>,\n",
      " 'z_dim': <absl.flags._flag.Flag object at 0x7f7cd0474a58>,\n",
      " 'z_dist': <absl.flags._flag.Flag object at 0x7f7cd0474b00>}\n",
      "Training with steerable G for shiftx transformation ...\n",
      "Results will be saved in shiftx_aug_argminW_lr0.0002\n",
      "rot2d aug is enabled\n",
      "loading mnist and augmenting ...\n",
      "first 10 idx.... [44072 47888 20480   871 16683 36841  3566  7586  5125 18850]\n",
      "Zoom train aug 20.0% progress\n",
      "Zoom train aug 40.0% progress\n",
      "Zoom train aug 60.0% progress\n",
      "Zoom train aug 80.0% progress\n",
      "Zoom test aug 33.333333333333336% progress\n",
      "Zoom test aug 66.66666666666667% progress\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e397cff0b74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tf.app.run(argv=['--transform_type', 'shiftx', '--dataset', 'mnist', '--train', '--input_height=28', '--output_height=28', '--train'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## I changed the default for mnist so shorter version is:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--transform_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shiftx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--aug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--epoch=100'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-588492de22f4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    106\u001b[0m           \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m           \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m           max_to_keep=FLAGS.max_to_keep)\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       dcgan = DCGAN(\n",
      "\u001b[0;32m~/ibig/ibig_git/gan_workspace/DCGAN-tensorflow/model_vanilla_shiftx.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, input_height, input_width, crop, batch_size, sample_num, output_height, output_width, y_dim, z_dim, gf_dim, df_dim, gfc_dim, dfc_dim, c_dim, dataset_name, aug, max_to_keep, input_fname_pattern, checkpoint_dir, sample_dir, out_dir, data_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rot2d aug is enabled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mnist_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rot2d aug is disabled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ibig/ibig_git/gan_workspace/DCGAN-tensorflow/model_vanilla_shiftx.py\u001b[0m in \u001b[0;36mload_mnist_aug\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0mteY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf.app.run(argv=['--transform_type', 'shiftx', '--dataset', 'mnist', '--train', '--input_height=28', '--output_height=28', '--train'])\n",
    "## I changed the default for mnist so shorter version is:\n",
    "tf.app.run(argv=['', '--transform_type', 'shiftx', '--aug', '--epoch=100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
