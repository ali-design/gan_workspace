{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model_steer2 import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "from ops import batch_norm\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, im_size=256, format='png', jpeg_fallback=True, filename=None):\n",
    "  if a.dtype != np.uint8:\n",
    "      a = a*255\n",
    "  a = np.asarray(a, dtype=np.uint8)\n",
    "  a = cv2.resize(a, (a.shape[1], a.shape[0]))\n",
    "\n",
    "  str_file = io.BytesIO()\n",
    "  PIL.Image.fromarray(a).save(str_file, format)\n",
    "  im_data = str_file.getvalue()\n",
    "  try:\n",
    "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    if filename:\n",
    "        size = (a.shape[1]//2, a.shape[0]//2)\n",
    "        im = PIL.Image.fromarray(a)\n",
    "        im.thumbnail(size,PIL.Image.ANTIALIAS)\n",
    "        im.save('{}.{}'.format(filename, format))\n",
    "        \n",
    "  except IOError:\n",
    "    if jpeg_fallback and format != 'jpeg':\n",
    "      print ('Warning: image was too large to display in format \"{}\"; '\n",
    "             'trying jpeg instead.').format(format)\n",
    "      return imshow(a, format='jpeg')\n",
    "    else:\n",
    "      raise\n",
    "  return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgrid(imarray, cols=5, pad=1):\n",
    "  if imarray.dtype != np.uint8:\n",
    "    raise ValueError('imgrid input imarray must be uint8')\n",
    "  pad = int(pad)\n",
    "  assert pad >= 0\n",
    "  cols = int(cols)\n",
    "  assert cols >= 1\n",
    "  N, H, W, C = imarray.shape\n",
    "  rows = int(np.ceil(N / float(cols)))\n",
    "  batch_pad = rows * cols - N\n",
    "  assert batch_pad >= 0\n",
    "  post_pad = [batch_pad, pad, pad, 0]\n",
    "  pad_arg = [[0, p] for p in post_pad]\n",
    "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n",
    "  H += pad\n",
    "  W += pad\n",
    "  grid = (imarray\n",
    "          .reshape(rows, cols, H, W, C)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(rows*H, cols*H, C))\n",
    "  if pad:\n",
    "    grid = grid[:-pad, :-pad]\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./out/shiftx_5px_argminGW_lr0.0002/checkpoint\"\n",
    "sample_dir = \"./out/shiftx_5px_argminGW_lr0.0002/sample\"\n",
    "num_samples = 10 # 1 sample per digit\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", num_samples, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# only for jupyter:\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcgan = DCGAN(\n",
    "#     sess,\n",
    "#     input_width=28,\n",
    "#     input_height=28,\n",
    "#     output_width=28,\n",
    "#     output_height=28,\n",
    "#     batch_size=64,\n",
    "#     sample_num=64,\n",
    "#     y_dim=10,\n",
    "#     z_dim=100,\n",
    "#     dataset_name='mnist',\n",
    "#     input_fname_pattern='*.jpg',\n",
    "#     crop=False,\n",
    "#     checkpoint_dir='20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64/checkpoint',\n",
    "# #     out_name='20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64',\n",
    "#     sample_dir='samples',\n",
    "#     data_dir='./data',\n",
    "#     out_dir='./out',\n",
    "#     max_to_keep=1)\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=num_samples,\n",
    "    y_dim=FLAGS.y_dim,\n",
    "    z_dim=FLAGS.z_dim,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir,\n",
    "    data_dir=FLAGS.data_dir,\n",
    "    out_dir=FLAGS.out_dir,\n",
    "    max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "if not load_success:\n",
    "    raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(sess, dcgan, FLAGS, 1, FLAGS.sample_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "# y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "y_one_hot = np.zeros((num_samples, FLAGS.y_dim))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "\n",
    "im_targets = []\n",
    "im_transformed = []\n",
    "lower_bound = -8\n",
    "alpha = np.tile(np.arange(lower_bound, -lower_bound+1, 1), [num_samples, 1])\n",
    "for i in range(alpha.shape[1]):\n",
    "    # get G and then targets:\n",
    "    samples = sess.run(dcgan.sampler, feed_dict = {dcgan.z: z_sample, dcgan.y: y_one_hot})    \n",
    "    targets, masks = dcgan.get_target_np(samples, np.expand_dims(alpha[:,i], axis=1))\n",
    "    im_targets.append(targets)\n",
    "    # get transformed:\n",
    "    samples = sess.run(dcgan.sampler_new, feed_dict = {dcgan.z: z_sample, \n",
    "                                                       dcgan.y: y_one_hot, \n",
    "                                                       dcgan.alpha: np.expand_dims(alpha[:,i],axis=1)})\n",
    "    im_transformed.append(samples)\n",
    "# imshow(imgrid(np.uint8(samples*255), cols=1))\n",
    "\n",
    "ims = []\n",
    "for j in range(FLAGS.y_dim):\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_targets], axis=0))\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_transformed], axis=0))\n",
    "\n",
    "print(alpha[0])\n",
    "imshow(imgrid(np.uint8(np.concatenate(ims)*255), cols=alpha.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
