{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import IPython.display\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, im_size=256, format='png', jpeg_fallback=True, filename=None):\n",
    "  a = a*255\n",
    "  a = np.asarray(a, dtype=np.uint8)\n",
    "  a = cv2.resize(a, (im_size, im_size))\n",
    "\n",
    "  str_file = io.BytesIO()\n",
    "  PIL.Image.fromarray(a).save(str_file, format)\n",
    "  im_data = str_file.getvalue()\n",
    "  try:\n",
    "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
    "    if filename:\n",
    "        size = (a.shape[1]//2, a.shape[0]//2)\n",
    "        im = PIL.Image.fromarray(a)\n",
    "        im.thumbnail(size,PIL.Image.ANTIALIAS)\n",
    "        im.save('{}.{}'.format(filename, format))\n",
    "        \n",
    "  except IOError:\n",
    "    if jpeg_fallback and format != 'jpeg':\n",
    "      print ('Warning: image was too large to display in format \"{}\"; '\n",
    "             'trying jpeg instead.').format(format)\n",
    "      return imshow(a, format='jpeg')\n",
    "    else:\n",
    "      raise\n",
    "  return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgrid(imarray, cols=5, pad=1):\n",
    "  if imarray.dtype != np.uint8:\n",
    "    raise ValueError('imgrid input imarray must be uint8')\n",
    "  pad = int(pad)\n",
    "  assert pad >= 0\n",
    "  cols = int(cols)\n",
    "  assert cols >= 1\n",
    "  N, H, W, C = imarray.shape\n",
    "  rows = int(np.ceil(N / float(cols)))\n",
    "  batch_pad = rows * cols - N\n",
    "  assert batch_pad >= 0\n",
    "  post_pad = [batch_pad, pad, pad, 0]\n",
    "  pad_arg = [[0, p] for p in post_pad]\n",
    "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values=255)\n",
    "  H += pad\n",
    "  W += pad\n",
    "  grid = (imarray\n",
    "          .reshape(rows, cols, H, W, C)\n",
    "          .transpose(0, 2, 1, 3, 4)\n",
    "          .reshape(rows*H, cols*W, C))\n",
    "  if pad:\n",
    "    grid = grid[:-pad, :-pad]\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        return not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./out/shiftx_5px_aug_inplace_lr0.0002/checkpoint\"\n",
    "sample_dir = \"./out/shiftx_5px_aug_inplace_lr0.0002/sample\"\n",
    "num_samples = 10 # 1 sample per digit\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", num_samples, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# only for jupyter:\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# flags = tf.app.flags\n",
    "# flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "# flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "# flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "# flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "# flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "# flags.DEFINE_integer(\"input_height\", 28, \"The size of image to use (will be center cropped). [108]\")\n",
    "# flags.DEFINE_integer(\"input_width\", 28, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "# flags.DEFINE_integer(\"output_height\", 28, \"The size of the output images to produce [64]\")\n",
    "# flags.DEFINE_integer(\"output_width\", 28, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "# flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "# flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "# flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "# flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "# flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "# # flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# # with aug:\n",
    "# # flags.DEFINE_string(\"checkpoint_dir\", \"./out/20190814.150034_data_mnist_x28.z100.uniform_signed.y28.b64_with_aug_inplace_5px_shift/checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# # without aug:\n",
    "# flags.DEFINE_string(\"checkpoint_dir\", \"./out/20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64_without_aug_5px_shift/checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "# # flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "# flags.DEFINE_string(\"sample_dir\", \"./out/20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64/samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "# flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "# flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "# flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "# flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "# flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "# flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "# flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "# flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "# flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "# flags.DEFINE_integer(\"y_dim\", 10, \"choose dimensions of y to be 10\")\n",
    "# flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "# flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "# #flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "# # only for jupyter:\n",
    "# flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "# FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints... ./out/shiftx_5px_aug_inplace_lr0.0002/checkpoint\n",
      "INFO:tensorflow:Restoring parameters from ./out/shiftx_5px_aug_inplace_lr0.0002/checkpoint/model.b64-27200\n",
      " [*] Success to read model.b64-27200\n"
     ]
    }
   ],
   "source": [
    "num_samples = FLAGS.batch_size # this is a bug, DCGAN.y placeholder is fixed to 64 but what if we want 1 sample?\n",
    "# dcgan = DCGAN(\n",
    "#     sess,\n",
    "#     input_width=28,\n",
    "#     input_height=28,\n",
    "#     output_width=28,\n",
    "#     output_height=28,\n",
    "#     batch_size=64,\n",
    "#     sample_num=64,\n",
    "#     y_dim=10,\n",
    "#     z_dim=100,\n",
    "#     dataset_name='mnist',\n",
    "#     input_fname_pattern='*.jpg',\n",
    "#     crop=False,\n",
    "#     checkpoint_dir='20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64/checkpoint',\n",
    "# #     out_name='20190813.180154_data_mnist_x28.z100.uniform_signed.y28.b64',\n",
    "#     sample_dir='samples',\n",
    "#     data_dir='./data',\n",
    "#     out_dir='./out',\n",
    "#     max_to_keep=1)\n",
    "dcgan = DCGAN(\n",
    "    sess,\n",
    "    input_width=FLAGS.input_width,\n",
    "    input_height=FLAGS.input_height,\n",
    "    output_width=FLAGS.output_width,\n",
    "    output_height=FLAGS.output_height,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    sample_num=num_samples,\n",
    "    y_dim=FLAGS.y_dim,\n",
    "    z_dim=FLAGS.z_dim,\n",
    "    dataset_name=FLAGS.dataset,\n",
    "    input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "    crop=FLAGS.crop,\n",
    "    checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "    sample_dir=FLAGS.sample_dir,\n",
    "    data_dir=FLAGS.data_dir,\n",
    "    out_dir=FLAGS.out_dir,\n",
    "    max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "if not load_success:\n",
    "    raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize(sess, dcgan, FLAGS, 1, FLAGS.sample_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26e0351278>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "y = np.random.choice(10, num_samples)\n",
    "y_one_hot = np.zeros((num_samples, 10))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "\n",
    "samples = sess.run(dcgan.sampler, feed_dict={dcgan.z: z_sample, dcgan.y: y_one_hot})\n",
    "plt.imshow(samples[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DCGAN' object has no attribute 'my_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-126f71af3638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# inputs_orig = {u'y': y_placeholder, u'z': z_placeholder}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# outputs_orig = dcgan.generator(inputs_orig)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutputs_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DCGAN' object has no attribute 'my_sampler'"
     ]
    }
   ],
   "source": [
    "z_placeholder = tf.placeholder(tf.float32, [None, FLAGS.z_dim], name='z_sample')\n",
    "y_placeholder = tf.placeholder(tf.float32, [FLAGS.batch_size, FLAGS.y_dim], name='y_sample')\n",
    "\n",
    "# inputs_orig = {u'y': y_placeholder, u'z': z_placeholder}\n",
    "# outputs_orig = dcgan.generator(inputs_orig)\n",
    "outputs_orig = dcgan.my_sampler(z_placeholder, y_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sess.run(outputs_orig, feed_dict={z_placeholder: z_sample, y_placeholder: y_one_hot})\n",
    "plt.imshow(samples[0,:,:,0])\n",
    "imshow(samples[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "Nsliders = 1\n",
    "target = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "mask = tf.placeholder(tf.float32, shape=(None, img_size, img_size, Nsliders))\n",
    "alpha = tf.placeholder(tf.float32, shape=None)\n",
    "w = tf.Variable(np.random.uniform(-1, 1, [1, FLAGS.z_dim]), name='walk', dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_new = z_placeholder+alpha*w\n",
    "y_new = y_placeholder\n",
    "transformed_output = dcgan.my_sampler(z_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.compute_weighted_loss(tf.square(transformed_output-target), weights=mask)\n",
    "lr = 0.05\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss, var_list=tf.trainable_variables(scope='walk'), \n",
    "                                                 name='AdamOpter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_initialized_vars = initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_np(outputs_zs, alpha, show_img=False, show_mask=False):\n",
    "    \n",
    "    mask_fn = np.ones(outputs_zs.shape)\n",
    "    print('outputs_zs.shape', outputs_zs.shape)\n",
    "    if alpha == 0:\n",
    "        return outputs_zs, mask_fn\n",
    "    \n",
    "    M = np.float32([[1,0,alpha],[0,1,0]])\n",
    "    target_fn = np.zeros(outputs_zs.shape)\n",
    "    mask_out = np.zeros(outputs_zs.shape)\n",
    "    for i in range(outputs_zs.shape[0]):\n",
    "        target_fn[i,:,:,:] = np.expand_dims(cv2.warpAffine(outputs_zs[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "        mask_out[i,:,:,:] = np.expand_dims(cv2.warpAffine(mask_fn[i,:,:,:], M, (img_size, img_size)), axis=2)\n",
    "\n",
    "    mask_out[np.nonzero(mask_out)] = 1.\n",
    "    assert(np.setdiff1d(mask_out, [0., 1.]).size == 0)\n",
    "        \n",
    "    if show_img:\n",
    "        print('Target image:')\n",
    "#         imshow_unscaled(target_fn)\n",
    "        imshow(target_fn[0,:,:,0], im_size=128)\n",
    "    if show_mask:\n",
    "        print('Target mask:')\n",
    "#         imshow_unscaled(mask_out)\n",
    "        imshow(mask_out[0,:,:,0], im_size=128)\n",
    "\n",
    "    return target_fn, mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p shift_l2_git/images\n",
    "! mkdir -p shift_l2_git/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be train.py\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/{1}.log\".format('shift_l2_git', 'train')),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "logger = logging.getLogger()\n",
    "\n",
    "alpha_list = []\n",
    "\n",
    "# train\n",
    "def train(saver):\n",
    "    # init zs\n",
    "    # we want couple of thousands per category, also compatible with batch_size\n",
    "    num_samples=12800\n",
    "    # sample inputs to feed to placeholders\n",
    "    zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "    # all categories\n",
    "    y = np.random.choice(10, num_samples)\n",
    "    ys = np.zeros((num_samples, 10))\n",
    "    ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "    Loss_sum = 0;\n",
    "    n_epoch = 1\n",
    "    optim_iter = 0\n",
    "    batch_size = 64\n",
    "    loss_values = []\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            alpha_val = np.random.randint(1, 6)  \n",
    "            coin = np.random.uniform(0, 1)\n",
    "            if coin <= 0.5:\n",
    "                alpha_val = -alpha_val\n",
    "\n",
    "            s = slice(batch_start, min(num_samples, batch_start + batch_size))\n",
    "\n",
    "            feed_dict_out = {z_placeholder: zs[s], y_placeholder: ys[s]}\n",
    "            out_zs = sess.run(outputs_orig, feed_dict_out)\n",
    "            \n",
    "            target_fn, mask_out = get_target_np(out_zs, alpha_val)#, show_img=True, show_mask=True)\n",
    "\n",
    "            feed_dict = {z_placeholder: zs[s], y_placeholder: ys[s], alpha: alpha_val, target: target_fn, mask: mask_out}\n",
    "            curr_loss, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "            Loss_sum = Loss_sum + curr_loss\n",
    "            loss_values.append(curr_loss)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            logger.info('T, epc, bst, lss, a: {}, {}, {}, {}, {}'.format(elapsed_time, epoch, batch_start, curr_loss, alpha_val))\n",
    "                \n",
    "            alpha_list.append(alpha_val)\n",
    "\n",
    "            if (optim_iter % 100 == 0) and (optim_iter > 0):\n",
    "                saver.save(sess, './shift_l2_git/model_{}.ckpt'.format(optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "\n",
    "            optim_iter = optim_iter+1\n",
    "            \n",
    "    if optim_iter > 0:\n",
    "        print('average loss with this metric: ', Loss_sum/(optim_iter*batch_size))\n",
    "    saver.save(sess, \"./shift_l2_git/model_{}_final.ckpt\".format(optim_iter*batch_size), write_meta_graph=False, write_state=False)\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dcgan.saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: show imgs \n",
    "saver.restore(sess, \"./shift_l2_git/model_12800_final.ckpt\")\n",
    "z_sample = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "# y = np.random.choice(FLAGS.y_dim, num_samples)\n",
    "y = np.arange(0,FLAGS.y_dim,1)\n",
    "y_one_hot = np.zeros((num_samples, FLAGS.y_dim))\n",
    "y_one_hot[np.arange(num_samples), y] = 1\n",
    "# print(y_one_hot)\n",
    "\n",
    "im_targets = []\n",
    "im_transformed = []\n",
    "lower_bound = -8\n",
    "alpha = np.tile(np.arange(lower_bound, -lower_bound+1, 1), [num_samples, 1])\n",
    "for i in range(alpha.shape[1]):\n",
    "    # get G and then targets:\n",
    "    samples = sess.run(dcgan.sampler, feed_dict = {dcgan.z: z_sample, dcgan.y: y_one_hot})    \n",
    "    targets, masks = dcgan.get_target_np(samples, np.expand_dims(alpha[:,i], axis=1))\n",
    "    im_targets.append(targets)\n",
    "    # get transformed:\n",
    "    samples = sess.run(dcgan.sampler_new, feed_dict = {dcgan.z: z_sample, \n",
    "                                                       dcgan.y: y_one_hot, \n",
    "                                                       dcgan.alpha: np.expand_dims(alpha[:,i],axis=1)})\n",
    "    im_transformed.append(samples)\n",
    "imshow(imgrid(np.uint8(samples*255), cols=1))\n",
    "\n",
    "ims = []\n",
    "for j in range(FLAGS.y_dim):\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_targets], axis=0))\n",
    "    ims.append(np.stack([x[j, :, :, :] for x in im_transformed], axis=0))\n",
    "\n",
    "print(alpha[0])\n",
    "imshow(imgrid(np.uint8(np.concatenate(ims)*255), cols=alpha.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: show imgs \n",
    "# this can be test.py\n",
    "\n",
    "np.random.seed(0)\n",
    "categories = np.random.choice(10, 10, replace=False)\n",
    "# categories = [449] # [207, 283, 751, 949, 963, 973, 970, 978]\n",
    "\n",
    "a = np.arange(-5,6,1)\n",
    " \n",
    "num_samples=64\n",
    "\n",
    "for c in range(len(categories)):\n",
    "\n",
    "    ims_zoomed = []\n",
    "    ims_target = []\n",
    "    ims_mask = []\n",
    "\n",
    "    zs = np.random.uniform(-1, 1, size=(num_samples, FLAGS.z_dim))\n",
    "\n",
    "    y = np.random.choice(10, num_samples)\n",
    "    ys = np.zeros((num_samples, 10))\n",
    "    ys[np.arange(num_samples), y] = 1\n",
    "\n",
    "    input_test = {y_placeholder: ys,\n",
    "                  z_placeholder: zs}\n",
    "    \n",
    "    out_input_test = sess.run(outputs_orig, input_test)\n",
    "    print('Input image:')    \n",
    "#     print(np.expand_dims(out_input_test[0,:,:,:], 0).shape)\n",
    "    # imshow_unscaled(np.expand_dims(out_input_test[0,:,:,:], 0))\n",
    "    \n",
    "    for i in range(a.shape[0]):\n",
    "        print('Target image with alpha={}:'.format(a[i]))\n",
    "        target_fn, mask_out = get_target_np(out_input_test, a[i], show_img=False)\n",
    "        best_inputs = {z_placeholder: zs, y_placeholder: ys, alpha: a[i], target: target_fn, mask: mask_out}#, input_step_sizes: step_sizes}\n",
    "        best_im_out, best_loss = sess.run([transformed_output, loss], best_inputs)\n",
    "        baseline_loss = sess.run(loss, feed_dict={mask: mask_out, target: target_fn, \n",
    "                                                  transformed_output: out_input_test})\n",
    "        \n",
    "        print('Transformed image with alpha={}, {}pix shift:'.format(a[i], a[i]))\n",
    "        # imshow_unscaled(np.expand_dims(best_im_out[0,:,:,:], 0))\n",
    "        # imshow_unscaled(best_im_out)\n",
    "        \n",
    "        # collect outputs\n",
    "        ims_zoomed.append(best_im_out)\n",
    "        ims_target.append(target_fn)\n",
    "        ims_mask.append(mask_out)\n",
    "    \n",
    "   # save image without mask\n",
    "    ims = []\n",
    "    for j in range(min(num_samples, 3)):\n",
    "        top_row = np.stack([x[j, :, :, :] for x in ims_target], axis=0)\n",
    "        top_row = np.uint8 (np.clip(((top_row + 1) / 2.0) * 256, 0, 255))\n",
    "        bottom_row = np.stack([x[j, :, :, :] for x in ims_zoomed], axis=0)\n",
    "        bottom_row = np.uint8(np.clip(((bottom_row + 1) / 2.0) * 256, 0, 255))\n",
    "        # add a green stripe down the center for alignment\n",
    "        _, _, width, _ = top_row.shape\n",
    "#         top_row[:, :, width//2-1:width//2+3, 0] = 255\n",
    "#         bottom_row[:, :, width//2-1:width//2+3, 0] = 255\n",
    "        ims.append(np.concatenate((top_row,bottom_row), axis=0))\n",
    "    ims = np.concatenate(ims, axis=0)\n",
    "    imshow(imgrid(ims, cols=len(a)), filename='shift_l2_git/images/grouped-{}-{}'.format(categories[c], 0))\n",
    "    \n",
    "    # save image with mask\n",
    "    ims = []\n",
    "    for j in range(min(num_samples, 3)):\n",
    "        top_row = np.stack([x[j, :, :, :] for x in ims_target], axis=0)\n",
    "        top_row = np.uint8 (np.clip(((top_row + 1) / 2.0) * 256, 0, 255))\n",
    "        bottom_row = np.stack([x[j, :, :, :] * y[j, :, :, :] for x, y in zip(ims_zoomed, ims_mask)], axis=0)\n",
    "        bottom_row = np.uint8(np.clip(((bottom_row + 1) / 2.0) * 256, 0, 255))\n",
    "        # add a green stripe down the center for alignment\n",
    "        _, _, width, _ = top_row.shape\n",
    "#         top_row[:, :, width//2-1:width//2+3, 0] = 255\n",
    "#         bottom_row[:, :, width//2-1:width//2+3, 0] = 255\n",
    "        ims.append(np.concatenate((top_row,bottom_row), axis=0))\n",
    "    ims = np.concatenate(ims, axis=0)\n",
    "    imshow(imgrid(ims, cols=len(a)), filename='shift_l2_git/images/grouped-{}-{}-mask'.format(categories[c], 0))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
