{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# from model import DCGAN\n",
    "from model_argminGW2_rot2d import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables, expand_path, timestamp\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_boolean(\"steer\", False, \"True for traning argminGW, False for training vanilla G\")\n",
    "flags.DEFINE_integer(\"epoch\", 25, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_float(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 108, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", \"mnist\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"./data\", \"path to datasets [e.g. $HOME/data]\")\n",
    "flags.DEFINE_string(\"out_dir\", \"./out\", \"Root directory for outputs [e.g. $HOME/out]\")\n",
    "flags.DEFINE_string(\"out_name\", \"\", \"Folder (under out_root_dir) for all outputs. Generated automatically if left blank []\")\n",
    "flags.DEFINE_boolean(\"aug\", False, \"True for enabling transformation augmentation\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Folder (under out_root_dir/out_name) to save checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Folder (under out_root_dir/out_name) to save samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_boolean(\"export\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_boolean(\"freeze\", False, \"True for exporting with new batch size\")\n",
    "flags.DEFINE_integer(\"max_to_keep\", 1, \"maximum number of checkpoints to keep\")\n",
    "flags.DEFINE_integer(\"sample_freq\", 200, \"sample every this many iterations\")\n",
    "flags.DEFINE_integer(\"ckpt_freq\", 200, \"save checkpoint every this many iterations\")\n",
    "flags.DEFINE_integer(\"z_dim\", 100, \"dimensions of z\")\n",
    "flags.DEFINE_string(\"z_dist\", \"uniform_signed\", \"'normal01' or 'uniform_unsigned' or uniform_signed\")\n",
    "flags.DEFINE_boolean(\"G_img_sum\", False, \"Save generator image summaries in log\")\n",
    "#flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  pp.pprint(flags.FLAGS.__flags)\n",
    "## ToDo: change this to accept T as arg and have only one main\n",
    "  if FLAGS.steer:\n",
    "    print('Training with steerable G -> loading model_argminGW2_zoom ...')\n",
    "    from model_argminGW2_rot2d import DCGAN\n",
    "  else:\n",
    "    print('Training vanilla G -> loading model_vanilla_zoom ...')\n",
    "    from model_vanilla_rot2d import DCGAN\n",
    "    \n",
    "  # expand user name and environment variables\n",
    "  FLAGS.data_dir = expand_path(FLAGS.data_dir)\n",
    "  FLAGS.out_dir = expand_path(FLAGS.out_dir)\n",
    "  FLAGS.out_name = expand_path(FLAGS.out_name)\n",
    "  FLAGS.checkpoint_dir = expand_path(FLAGS.checkpoint_dir)\n",
    "  FLAGS.sample_dir = expand_path(FLAGS.sample_dir)\n",
    "\n",
    "  print('FLAGS.dataset:', FLAGS.dataset)  \n",
    "  print('FLAGS.output_height', FLAGS.output_height)  \n",
    "  print('flags.train', FLAGS.train)\n",
    "\n",
    "  if FLAGS.output_height is None: FLAGS.output_height = FLAGS.input_height\n",
    "  if FLAGS.input_width is None: FLAGS.input_width = FLAGS.input_height\n",
    "  if FLAGS.output_width is None: FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "  # output folders\n",
    "  if FLAGS.out_name == \"\":\n",
    "      FLAGS.out_name = '{} - {} - {}'.format(timestamp(), FLAGS.data_dir.split('/')[-1], FLAGS.dataset) # penultimate folder of path\n",
    "      if FLAGS.train:\n",
    "        FLAGS.out_name += ' - x{}.z{}.{}.y{}.b{}'.format(FLAGS.input_width, FLAGS.z_dim, FLAGS.z_dist, FLAGS.output_width, FLAGS.batch_size)\n",
    "\n",
    "  FLAGS.out_dir = os.path.join(FLAGS.out_dir, FLAGS.out_name)\n",
    "  FLAGS.checkpoint_dir = os.path.join(FLAGS.out_dir, FLAGS.checkpoint_dir)\n",
    "  FLAGS.sample_dir = os.path.join(FLAGS.out_dir, FLAGS.sample_dir)\n",
    "\n",
    "  if not os.path.exists(FLAGS.checkpoint_dir): os.makedirs(FLAGS.checkpoint_dir)\n",
    "  if not os.path.exists(FLAGS.sample_dir): os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "  with open(os.path.join(FLAGS.out_dir, 'FLAGS.json'), 'w') as f:\n",
    "    flags_dict = {k:FLAGS[k].value for k in FLAGS}\n",
    "    json.dump(flags_dict, f, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "  \n",
    "\n",
    "  #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "  run_config = tf.ConfigProto()\n",
    "  run_config.gpu_options.allow_growth=True\n",
    "\n",
    "  with tf.Session(config=run_config) as sess:\n",
    "    if FLAGS.dataset == 'mnist':\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          input_width=FLAGS.input_width,\n",
    "          input_height=FLAGS.input_height,\n",
    "          output_width=FLAGS.output_width,\n",
    "          output_height=FLAGS.output_height,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          y_dim=10,\n",
    "          z_dim=FLAGS.z_dim,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          aug=FLAGS.aug,          \n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          data_dir=FLAGS.data_dir,\n",
    "          out_dir=FLAGS.out_dir,\n",
    "          max_to_keep=FLAGS.max_to_keep)\n",
    "    else:\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          input_width=FLAGS.input_width,\n",
    "          input_height=FLAGS.input_height,\n",
    "          output_width=FLAGS.output_width,\n",
    "          output_height=FLAGS.output_height,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          z_dim=FLAGS.z_dim,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          data_dir=FLAGS.data_dir,\n",
    "          out_dir=FLAGS.out_dir,\n",
    "          max_to_keep=FLAGS.max_to_keep)\n",
    "\n",
    "    show_all_variables()\n",
    "\n",
    "    if FLAGS.train:\n",
    "      dcgan.train(FLAGS)\n",
    "    else:\n",
    "      load_success, load_counter = dcgan.load(FLAGS.checkpoint_dir)\n",
    "      if not load_success:\n",
    "        raise Exception(\"Checkpoint not found in \" + FLAGS.checkpoint_dir)\n",
    "\n",
    "\n",
    "    # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
    "    #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
    "    #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
    "    #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
    "    #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
    "\n",
    "    # Below is codes for visualization\n",
    "      if FLAGS.export:\n",
    "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'export_b'+str(FLAGS.batch_size))\n",
    "        dcgan.save(export_dir, load_counter, ckpt=True, frozen=False)\n",
    "\n",
    "      if FLAGS.freeze:\n",
    "        export_dir = os.path.join(FLAGS.checkpoint_dir, 'frozen_b'+str(FLAGS.batch_size))\n",
    "        dcgan.save(export_dir, load_counter, ckpt=False, frozen=True)\n",
    "\n",
    "      if FLAGS.visualize:\n",
    "        OPTION = 1\n",
    "        visualize(sess, dcgan, FLAGS, OPTION, FLAGS.sample_dir)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.app.run(argv=['--dataset', 'mnist', '--input_height=28', '--output_height=28', '--train', '--out_name=argGW_rot2d', '--aug', '-steer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir ./out/ckpt/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python main.py --dataset mnist --input_height 28 --output_height=28 --train --out_name zoom_argminGW_lr0.0002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
